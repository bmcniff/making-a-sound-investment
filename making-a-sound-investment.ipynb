{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad15488f-51ee-4e20-abfd-9a419ab37129",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "I've spent the past fifteen or so years collecting, trading, and obsessing over music equipment. This means that I've spent a good amount of time online looking at what I can add to my collection. One of the largest online marketplaces for music equipment is Reverb. Reverb allows users to make posts at no cost as well as offers a platform for price tracking, negotiation, and general music equipment exploration.\n",
    "\n",
    "Having been on both sides of the Reverb marketplace, I've found that selling equipment is significantly harder due to the competition you face with other sellers. I've often wondered in the past if there are any important features to highlight or settings to enable that would give my posts an advantage in a sea of similar equipment.\n",
    "\n",
    "The goal for this project is to develop a predictive model to classify whether a product is likely to sell based on the post information and product details. To start, I'm importing the libraries we'll need and importing a list of links to a couple thousand posts.\n",
    "\n",
    "Before jumping into the code, I'll quickly explain my data collection strategy for this project. Ensuring that the products in this dataset are as similar as possible is crucial. The features that are important for a keyboard may be totally irrelevant for a drum set. For this reason, I did some research on the most popular products currently on Reverb and found that the \"Fender American Professional II Stratocaster\" was one of the most popular. The website has about 1,000 current listings up, and about 1,300 sold listings archived for this product. Now we can get into the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "id": "204fda19-5119-40c6-b1be-12b9632a5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dcb68e-de4a-438b-9363-b140e1e5f174",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "Using the Chrome WebScraper extension, I iterated through each page of the search results to collect a list of links. Here, I am parsing each of those lists into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "264b6438-b173-438f-b057-db02e4534f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_links = pd.read_csv('/Users/brianmcniff/Downloads/reverb_strat.csv')\n",
    "scraped_links['post_id'] = [link.split('/')[4].split('-')[0] for link in scraped_links['links-href']]\n",
    "scraped_links['post_id_int'] = [int(post_id) for post_id in scraped_links['post_id']]\n",
    "\n",
    "scraped_links_sold = pd.read_csv('/Users/brianmcniff/Downloads/reverb_strat_sold.csv')\n",
    "scraped_links_sold['post_id'] = [link.split('/')[4].split('-')[0] for link in scraped_links_sold['links-href']]\n",
    "scraped_links_sold['post_id_int'] = [int(post_id) for post_id in scraped_links_sold['post_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77387200-29c4-43cd-a9e3-2a12d48792b3",
   "metadata": {},
   "source": [
    "By referencing Reverb's API, I created a function to pull all info for a given post. I've included the first chunk of the response below, but this is quite long so we'll explore all relevant info later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "id": "6110ea7d-b544-4767-acee-a0f8be94c5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":73348569,\"make\":\"Fender\",\"model\":\"Miami Blue American Professional II Stratocaster\",\"finish\":\"Miami Blue\",\"year\":\"2021\",\"title\":\"Miami Blue Fender American Professional II Stratocaster\",\"created_at\":\"2023-09-11T10:15:00-05:00\",\"shop_name\":\"Kev’s Killer Guitars\",\"shop\":{\"feedback_count\":31,\"preferred_seller\":false,\"rating_percentage\":1.0},\"description\":\"<p>You won’t find a nicer Rosewood fretboard on a new Strat! The grain and color are gorgeous. One owner! This is a 2021 (75th Anniversary)'"
      ]
     },
     "execution_count": 1238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_post_info(id):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/hal+json',\n",
    "        'Accept': 'application/hal+json',\n",
    "        'Accept-Version': '3.0',\n",
    "        'Authorization': 'Bearer secret_key'\n",
    "    }\n",
    "\n",
    "    response = requests.get(f'https://api.reverb.com/api/listings/{id}', headers=headers)\n",
    "    return response.text\n",
    "\n",
    "test_row = get_post_info(73348569)\n",
    "test_row[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c1f6d-7c78-4265-a2a0-c946392a6029",
   "metadata": {},
   "source": [
    "Iterating through each of our links, we can pull in all data for each product that matches our requirements. It's worth noting that although we are not hitting Reverb with a massive number of requests, it's still worth saving this to disk to avoid making additional requests for the same posts in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "41bb7154-b9af-475d-a252-a60fb8cc1263",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_post_info = {}\n",
    "\n",
    "for post in scraped_links['post_id']:\n",
    "    all_post_info[post] = get_post_info(post)\n",
    "\n",
    "all_sold_post_info = {}\n",
    "\n",
    "for post in scraped_links_sold['post_id']:\n",
    "    all_sold_post_info[post] = get_post_info(post)\n",
    "    \n",
    "# save/load dict from disk to avoid duplicating API calls\n",
    "with open('reverb_all_post_info.pkl', 'wb') as f:\n",
    "    pickle.dump(all_post_info, f)\n",
    "        \n",
    "# with open('reverb_all_post_info.pkl', 'rb') as f:\n",
    "#     all_post_info_from_disk = pickle.load(f)\n",
    "\n",
    "with open('reverb_all_sold_post_info.pkl', 'wb') as f:\n",
    "    pickle.dump(all_sold_post_info, f)\n",
    "        \n",
    "# with open('reverb_all_post_info.pkl', 'rb') as f:\n",
    "#     all_post_info_from_disk = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01827542-4267-4c44-83a5-b7b59876e7df",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "The next step is to parse this JSON into a dataframe. Luckily, the json_normalize function does exactly what I need right out of the box. We again iterate through each post in our JSON response, and add a row for each post to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "id": "36c935e1-b96e-4a53-a023-e284e3749e48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def json_to_df(json_response, post_id):\n",
    "    posting = {}\n",
    "    for field, value in json.loads(json_response[post_id]).items():\n",
    "        posting[field] = value\n",
    "\n",
    "    posting_df = pd.json_normalize(posting)\n",
    "\n",
    "    return posting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "id": "71c8deb6-bb40-4fd0-a3a1-76678b6ebf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty post dataframe using keys from JSON response\n",
    "for field, value in json.loads(test_row).items():\n",
    "    posting[field] = value\n",
    "\n",
    "posting_df = pd.json_normalize(posting)\n",
    "posting_df = df.drop(index = 0)\n",
    "\n",
    "for post_id in all_post_info:\n",
    "    df_row = json_to_df(all_post_info, post_id)\n",
    "    posting_df = pd.concat([posting_df, df_row], ignore_index=True)\n",
    "    \n",
    "# create empty sold post dataframe using keys from JSON response\n",
    "for field, value in json.loads(test_row).items():\n",
    "    posting[field] = value\n",
    "\n",
    "sold_posting_df = pd.json_normalize(posting)\n",
    "sold_posting_df = df.drop(index = 0)\n",
    "\n",
    "for post_id in all_sold_post_info:\n",
    "    df_row = json_to_df(all_sold_post_info, post_id)\n",
    "    sold_posting_df = pd.concat([sold_posting_df, df_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79b6b9-3bcb-42ad-8db6-39e1326504d2",
   "metadata": {},
   "source": [
    "One important note to make is that current posts (products still for sale) that were recently added are not good indicators of unsold products since they may still sell given enough time. For this reason, I decided to remove all open posts from the past three months, just to increase the confidence that our unsold products are far less likely to convert to sold products.\n",
    "\n",
    "We're also merging our sold and non-sold dataframes into one here, with the inclusion of an \"is_sold\" field (which will become our dependent variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "id": "dbc96940-cc06-4a05-88dc-294adb550290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove recently added but not yet sold guitars (may convert to sold guitars given enough time)\n",
    "posting_df = posting_df[pd.to_datetime(posting_df['created_at']) < pd.to_datetime('2023-07-01 00:00:00-04:00')].copy()\n",
    "\n",
    "posting_df['is_sold'] = 0\n",
    "sold_posting_df['is_sold'] = 1\n",
    "\n",
    "all_posting_df = pd.concat([posting_df, sold_posting_df],join='inner', ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414b204-13a1-45d3-b89c-b2c7c70b5909",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "After exploring the data, there are a handful of ideas I have for additional features. It's likely that many of these will go unused, but absolutely worth experimenting with to see. The purpose of each feature is explained with inline comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "id": "ac32f4c2-78ae-4a20-99ff-3c9bd80de7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# character length of title and description\n",
    "all_posting_df['len_title'] = [len(post) for post in all_posting_df['title']]\n",
    "all_posting_df['len_description'] = [len(post) for post in all_posting_df['description']]\n",
    "\n",
    "# number of photos and videos in post\n",
    "all_posting_df['num_photos'] = [len(post) for post in all_posting_df['cloudinary_photos']]\n",
    "all_posting_df['num_videos'] = [len(post) for post in all_posting_df['videos']]\n",
    "\n",
    "# boolean for each payment type accepted\n",
    "all_posting_df['direct_checkout_accepted'] = ['direct_checkout' in accepted_list for accepted_list in all_posting_df['accepted_payment_methods']]\n",
    "all_posting_df['paypal_accepted'] = ['paypal' in accepted_list for accepted_list in all_posting_df['accepted_payment_methods']]\n",
    "all_posting_df['affirm_accepted'] = ['affirm' in accepted_list for accepted_list in all_posting_df['accepted_payment_methods']]\n",
    "all_posting_df['klarna_accepted'] = ['klarna_account' in accepted_list for accepted_list in all_posting_df['accepted_payment_methods']]\n",
    "\n",
    "# truncating year for cleaner grouping\n",
    "all_posting_df['year_trunc'] = [str(year)[:4].lower() for year in all_posting_df['year']]\n",
    "\n",
    "# title mentions including a case\n",
    "all_posting_df['includes_case'] = ['case' in title.lower() for title in all_posting_df['title']]\n",
    "\n",
    "# percent difference between current price and original price\n",
    "all_posting_df['price_drop_percent'] = 1.0 - (all_posting_df['price.amount'].astype(float) / all_posting_df['original_price.amount'].astype(float))\n",
    "\n",
    "# formatting finishes for cleaner grouping\n",
    "finish_list = []\n",
    "\n",
    "for post in all_posting_df['finish']:\n",
    "    if   'burst' in post.lower():\n",
    "        finish_list.append('Sunburst')\n",
    "    elif 'dark' in post.lower():\n",
    "        finish_list.append('Dark Night')\n",
    "    elif 'black' in post.lower():\n",
    "        finish_list.append('Black')\n",
    "    elif 'blue' in post.lower():\n",
    "        finish_list.append('Miami Blue')\n",
    "    elif 'miami' in post.lower():\n",
    "        finish_list.append('Miami Blue')\n",
    "    elif 'green' in post.lower():\n",
    "        finish_list.append('Mystic Surf Green')\n",
    "    elif 'white' in post.lower():\n",
    "        finish_list.append('Olympic White')\n",
    "    elif 'pine' in post.lower():\n",
    "        finish_list.append('Roasted Pine')\n",
    "    else:\n",
    "        finish_list.append('Other')\n",
    "        \n",
    "all_posting_df['finish_formatted'] = finish_list\n",
    "\n",
    "# extracting number of days from return policy\n",
    "days_to_return = [re.findall(r'\\d+', post) for post in all_posting_df['return_policy.description']]\n",
    "all_posting_df['days_to_return_int'] = [int(post[0]) if len(post) > 0 else 0 for post in days_to_return]\n",
    "\n",
    "# checking whether coupon code is available\n",
    "all_posting_df['has_coupon_code'] = pd.isna(all_posting_df['coupon.code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90484f5e-0d6d-44df-b8c1-bf948fbe42e6",
   "metadata": {},
   "source": [
    "It's also good to take some time to remove any columns that are just going to create noise or contribute very little. I've done this systematically by removing features with unique values on each row, and removing features that only have one unique value. I then went through each feature in the datasource and manually excluded any redundant fields (for example, \"price\", \"price_in_cents\", \"price_label\", etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "id": "5f734ee3-47b0-42a5-b528-6cfaa5723847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing id columns\n",
    "id_columns = all_posting_df.columns[all_posting_df.astype('string').nunique(dropna=False) == 1015]\n",
    "all_posting_df = all_posting_df.drop(columns=id_columns)\n",
    "\n",
    "# removing columns with only a single unique value\n",
    "columns_w_one_value = all_posting_df.columns[all_posting_df.astype('string').nunique(dropna=False) <= 1]\n",
    "all_posting_df = all_posting_df.drop(columns=columns_w_one_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "id": "26331131-f21f-4d71-90a6-075c7cf7f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['inventory',\n",
    "        'has_inventory',\n",
    "        'offers_enabled',\n",
    "        'listing_currency',\n",
    "        'handmade',\n",
    "        'local_pickup_only',\n",
    "        'sold_as_is',\n",
    "        'upc_does_not_apply',\n",
    "        'origin_country_code',\n",
    "        'same_day_shipping_ineligible',\n",
    "        'shop.feedback_count',\n",
    "        'shop.preferred_seller',\n",
    "        'shop.rating_percentage',\n",
    "        'condition.display_name',\n",
    "        'price.amount',\n",
    "        'shipping.free_expedited_shipping',\n",
    "        'shipping.local',\n",
    "        'shipping.user_region_rate.region_code',\n",
    "        'shipping.user_region_rate.rate.amount',\n",
    "        'shipping.user_region_rate.regional',\n",
    "        'shipping.user_region_rate.destination_postal_code_needed',\n",
    "        'location.country_code',\n",
    "        'original_price.amount',\n",
    "        'price_drop_percent',\n",
    "        'len_title',\n",
    "        'len_description',\n",
    "        'num_photos',\n",
    "        'direct_checkout_accepted',\n",
    "        'paypal_accepted',\n",
    "        'affirm_accepted',\n",
    "        'klarna_accepted',\n",
    "        'year_trunc',\n",
    "        'includes_case',\n",
    "        'finish_formatted',\n",
    "        'days_to_return_int',\n",
    "        'has_coupon_code']\n",
    "\n",
    "X = all_posting_df[feature_cols]\n",
    "y = all_posting_df['is_sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a08dd-0439-49d3-9e9e-52d61cf8e157",
   "metadata": {},
   "source": [
    "Fortunately all of the fields that require missing value imputation have a reasonable value to impute. For example, if 'original_price' is missing, we can assume there is no original price, since the product's price hasn't changed. Another example is for \"handmade\". It's safe to assume that a handmade guitar would use this as its main selling point, so I don't expect to see many handmade guitars with that field missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "id": "7578a9f0-d76c-4382-a4cb-99761c5e9bd9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/411myfb10_18fz7bnd_tnmqh0000gn/T/ipykernel_14980/2228620318.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['handmade'] = X['handmade'].fillna(False)\n",
      "/var/folders/hc/411myfb10_18fz7bnd_tnmqh0000gn/T/ipykernel_14980/2228620318.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['upc_does_not_apply'] = X['upc_does_not_apply'].fillna(False)\n",
      "/var/folders/hc/411myfb10_18fz7bnd_tnmqh0000gn/T/ipykernel_14980/2228620318.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['shipping.user_region_rate.regional'] = X['shipping.user_region_rate.regional'].fillna(False)\n",
      "/var/folders/hc/411myfb10_18fz7bnd_tnmqh0000gn/T/ipykernel_14980/2228620318.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['shipping.user_region_rate.destination_postal_code_needed'] = X['shipping.user_region_rate.destination_postal_code_needed'].fillna(False)\n",
      "/var/folders/hc/411myfb10_18fz7bnd_tnmqh0000gn/T/ipykernel_14980/2228620318.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['original_price.amount'] = X['original_price.amount'].fillna(X['price.amount'])\n",
      "/var/folders/hc/411myfb10_18fz7bnd_tnmqh0000gn/T/ipykernel_14980/2228620318.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['price_drop_percent'] = X['price_drop_percent'].fillna(0)\n",
      "/var/folders/hc/411myfb10_18fz7bnd_tnmqh0000gn/T/ipykernel_14980/2228620318.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['shipping.user_region_rate.rate.amount'] = X['shipping.user_region_rate.rate.amount'].fillna(0)\n",
      "/var/folders/hc/411myfb10_18fz7bnd_tnmqh0000gn/T/ipykernel_14980/2228620318.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['shipping.user_region_rate.region_code'] = X['shipping.user_region_rate.region_code'].fillna('missing')\n",
      "/var/folders/hc/411myfb10_18fz7bnd_tnmqh0000gn/T/ipykernel_14980/2228620318.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['origin_country_code'] = X['origin_country_code'].fillna('missing')\n"
     ]
    }
   ],
   "source": [
    "# impute missing values\n",
    "X['handmade'] = X['handmade'].fillna(False)\n",
    "X['upc_does_not_apply'] = X['upc_does_not_apply'].fillna(False)\n",
    "X['shipping.user_region_rate.regional'] = X['shipping.user_region_rate.regional'].fillna(False)\n",
    "X['shipping.user_region_rate.destination_postal_code_needed'] = X['shipping.user_region_rate.destination_postal_code_needed'].fillna(False)\n",
    "\n",
    "X['original_price.amount'] = X['original_price.amount'].fillna(X['price.amount'])\n",
    "\n",
    "X['price_drop_percent'] = X['price_drop_percent'].fillna(0)\n",
    "X['shipping.user_region_rate.rate.amount'] = X['shipping.user_region_rate.rate.amount'].fillna(0)\n",
    "\n",
    "X['shipping.user_region_rate.region_code'] = X['shipping.user_region_rate.region_code'].fillna('missing')\n",
    "X['origin_country_code'] = X['origin_country_code'].fillna('missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e8dd8-a45f-4bd8-95b1-57a94a445f63",
   "metadata": {},
   "source": [
    "Preparing for one-hot encoding, I separated out all of the categorical columns and ran each through a function that encodes and removes the original field from our dataframe. The resulting columns are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "id": "ea5b9dd6-70ec-4fac-b0c7-9252b14ca929",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'has_inventory', \n",
    "    'offers_enabled', \n",
    "    'listing_currency',\n",
    "    'handmade', \n",
    "    'local_pickup_only', \n",
    "    'sold_as_is', \n",
    "    'upc_does_not_apply',\n",
    "    'origin_country_code', \n",
    "    'same_day_shipping_ineligible',\n",
    "    'shop.preferred_seller',\n",
    "    'condition.display_name',\n",
    "    'shipping.free_expedited_shipping',\n",
    "    'shipping.local', \n",
    "    'shipping.user_region_rate.region_code',\n",
    "    'shipping.user_region_rate.regional',\n",
    "    'shipping.user_region_rate.destination_postal_code_needed',\n",
    "    'location.country_code', \n",
    "    'direct_checkout_accepted', \n",
    "    'paypal_accepted', \n",
    "    'affirm_accepted',\n",
    "    'klarna_accepted', \n",
    "    'year_trunc', \n",
    "    'includes_case', \n",
    "    'finish_formatted', \n",
    "    'has_coupon_code'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "id": "2cc44579-6bc5-48ca-9316-129a80d841ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, col_name):\n",
    "    one_hot_df = pd.get_dummies(data=df[col_name], prefix=col_name, prefix_sep='_', drop_first=True)\n",
    "    df = df.drop(columns=[col_name])\n",
    "    df = pd.merge(left=df, right=one_hot_df, left_index=True, right_index=True, how='inner')\n",
    "    return df\n",
    "\n",
    "for col in categorical_columns:\n",
    "    X = one_hot_encode(X, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "id": "25cad9c2-9d9a-45aa-8ff4-03ba3c2effb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['inventory', 'shop.feedback_count', 'shop.rating_percentage',\n",
       "       'price.amount', 'shipping.user_region_rate.rate.amount',\n",
       "       'original_price.amount', 'price_drop_percent', 'len_title',\n",
       "       'len_description', 'num_photos', 'days_to_return_int',\n",
       "       'has_inventory_True', 'offers_enabled_True', 'listing_currency_CAD',\n",
       "       'listing_currency_EUR', 'listing_currency_GBP', 'listing_currency_JPY',\n",
       "       'listing_currency_USD', 'handmade_True', 'local_pickup_only_True',\n",
       "       'sold_as_is_True', 'upc_does_not_apply_True',\n",
       "       'origin_country_code_missing', 'same_day_shipping_ineligible_True',\n",
       "       'shop.preferred_seller_True', 'condition.display_name_Brand New',\n",
       "       'condition.display_name_Excellent', 'condition.display_name_Good',\n",
       "       'condition.display_name_Mint', 'condition.display_name_Very Good',\n",
       "       'shipping.free_expedited_shipping_True', 'shipping.local_True',\n",
       "       'shipping.user_region_rate.region_code_US',\n",
       "       'shipping.user_region_rate.region_code_US_CON',\n",
       "       'shipping.user_region_rate.region_code_XX',\n",
       "       'shipping.user_region_rate.region_code_missing',\n",
       "       'shipping.user_region_rate.regional_True',\n",
       "       'shipping.user_region_rate.destination_postal_code_needed_True',\n",
       "       'location.country_code_CA', 'location.country_code_DE',\n",
       "       'location.country_code_ES', 'location.country_code_FR',\n",
       "       'location.country_code_GB', 'location.country_code_IT',\n",
       "       'location.country_code_JP', 'location.country_code_LT',\n",
       "       'location.country_code_MT', 'location.country_code_NL',\n",
       "       'location.country_code_US', 'direct_checkout_accepted_True',\n",
       "       'paypal_accepted_True', 'affirm_accepted_True', 'klarna_accepted_True',\n",
       "       'year_trunc_0', 'year_trunc_2018', 'year_trunc_2019', 'year_trunc_2020',\n",
       "       'year_trunc_2021', 'year_trunc_2022', 'year_trunc_2023',\n",
       "       'year_trunc_new', 'includes_case_True', 'finish_formatted_Dark Night',\n",
       "       'finish_formatted_Miami Blue', 'finish_formatted_Mystic Surf Green',\n",
       "       'finish_formatted_Olympic White', 'finish_formatted_Other',\n",
       "       'finish_formatted_Roasted Pine', 'finish_formatted_Sunburst',\n",
       "       'has_coupon_code_True'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db7fca-dc2a-4158-bed2-a1c03b4a7844",
   "metadata": {},
   "source": [
    "Lastly, we'll need to partition our data into train and test groups. Since I'm going to be experimenting with this a good amount, I'm going to use a training and validation set, and employ a third test set as a final check at the end of the project. This helps to further ensure that our model is not overfitting to data it's familiar with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "id": "29eb6489-8e6a-45f7-bf71-1a2211f0751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=100)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ca4b19-1545-4c4c-9c84-0916a76adc70",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "My plan for this part of the process is to start with a baseline logistic regression model to see how it performs. Ideally, we can use this model to reduce our features to the most important ones as well. We'll be using F1 score and a confusion matrix to interpret our model's performance across each change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "id": "8b8537ae-3ac9-4278-9110-d43f389c181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score:\t0.9986824769433464\n",
      "Validation F1 Score: \t0.9980119284294234\n",
      "[[158   1]\n",
      " [  0 251]]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=10000, random_state=100)\n",
    "logreg.fit(X_train.astype(float), y_train)\n",
    "y_pred_train = logreg.predict(X_train.astype(float))\n",
    "y_pred_val = logreg.predict(X_val.astype(float))\n",
    "\n",
    "print('Training F1 Score:\\t{}'.format(f1_score(y_train, y_pred_train)))\n",
    "print('Validation F1 Score: \\t{}'.format(f1_score(y_val, y_pred_val)))\n",
    "print(confusion_matrix(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b227b95-f9be-44b9-b4a8-5391f234e96a",
   "metadata": {},
   "source": [
    "Wow! This is a great F1 score! ...suspiciously great. My assumption is that one of our fields is contributing to data leakage and causing our model to perform unrealistically well. In order to determine which field may be causing this, let's first employ some feature selection to narrow down which fields are doing the heavy lifting. \n",
    "\n",
    "I also want to acknowledge that I'm setting the max_iter parameter in our model fairly high because the model is throwing a warning that it doesn't have enough iterations to converge. If this were a larger more resource intensive dataset/model, a more performant approach would be to scale our data for convergence in less iterations, but this is taking less than a minute either way, so this solution will work for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "id": "68836337-b5a4-45c7-9cfc-e06577096433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inventory</th>\n",
       "      <th>shop.rating_percentage</th>\n",
       "      <th>price.amount</th>\n",
       "      <th>shipping.user_region_rate.rate.amount</th>\n",
       "      <th>original_price.amount</th>\n",
       "      <th>price_drop_percent</th>\n",
       "      <th>len_title</th>\n",
       "      <th>num_photos</th>\n",
       "      <th>days_to_return_int</th>\n",
       "      <th>offers_enabled_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.996569</td>\n",
       "      <td>1529.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1529.99</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.991469</td>\n",
       "      <td>1699.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1699.99</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.991322</td>\n",
       "      <td>1259.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1339.99</td>\n",
       "      <td>0.059702</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991322</td>\n",
       "      <td>1259.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1339.99</td>\n",
       "      <td>0.059702</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.991322</td>\n",
       "      <td>1259.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1259.99</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1350.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1600.00</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>0</td>\n",
       "      <td>0.988374</td>\n",
       "      <td>1699.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1699.99</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>0</td>\n",
       "      <td>0.982306</td>\n",
       "      <td>1199.99</td>\n",
       "      <td>90.00</td>\n",
       "      <td>1399.99</td>\n",
       "      <td>0.142858</td>\n",
       "      <td>62</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>0</td>\n",
       "      <td>0.997531</td>\n",
       "      <td>1199.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>1264.00</td>\n",
       "      <td>0.051424</td>\n",
       "      <td>86</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>0</td>\n",
       "      <td>0.996819</td>\n",
       "      <td>1299.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>1299.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2051 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      inventory  shop.rating_percentage price.amount  \\\n",
       "0             1                0.996569      1529.99   \n",
       "1             1                0.991469      1699.99   \n",
       "2             1                0.991322      1259.99   \n",
       "3             0                0.991322      1259.99   \n",
       "4             4                0.991322      1259.99   \n",
       "...         ...                     ...          ...   \n",
       "2046          0                1.000000      1350.00   \n",
       "2047          0                0.988374      1699.99   \n",
       "2048          0                0.982306      1199.99   \n",
       "2049          0                0.997531      1199.00   \n",
       "2050          0                0.996819      1299.00   \n",
       "\n",
       "     shipping.user_region_rate.rate.amount original_price.amount  \\\n",
       "0                                     0.00               1529.99   \n",
       "1                                     0.00               1699.99   \n",
       "2                                     0.00               1339.99   \n",
       "3                                     0.00               1339.99   \n",
       "4                                     0.00               1259.99   \n",
       "...                                    ...                   ...   \n",
       "2046                                100.00               1600.00   \n",
       "2047                                  0.00               1699.99   \n",
       "2048                                 90.00               1399.99   \n",
       "2049                                 36.00               1264.00   \n",
       "2050                                 45.00               1299.00   \n",
       "\n",
       "      price_drop_percent  len_title  num_photos  days_to_return_int  \\\n",
       "0               0.000000         68          11                  30   \n",
       "1               0.000000         90           9                  30   \n",
       "2               0.059702         80           5                  30   \n",
       "3               0.059702         74           5                  30   \n",
       "4               0.000000         77           5                  30   \n",
       "...                  ...        ...         ...                 ...   \n",
       "2046            0.156250         82           5                   7   \n",
       "2047            0.000000         88          10                  14   \n",
       "2048            0.142858         62          14                   0   \n",
       "2049            0.051424         86           8                   1   \n",
       "2050            0.000000         54          11                  30   \n",
       "\n",
       "      offers_enabled_True  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       1  \n",
       "3                       1  \n",
       "4                       1  \n",
       "...                   ...  \n",
       "2046                    0  \n",
       "2047                    0  \n",
       "2048                    1  \n",
       "2049                    0  \n",
       "2050                    1  \n",
       "\n",
       "[2051 rows x 10 columns]"
      ]
     },
     "execution_count": 1169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_sfs = LogisticRegression(max_iter = 10000, random_state=100)\n",
    "sfs = SequentialFeatureSelector(logreg_sfs, n_features_to_select=10)\n",
    "sfs.fit(X, y)\n",
    "included_features = sfs.get_support()\n",
    "X.iloc[:,included_features]\n",
    "included_features_init = included_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a6dc3-59f5-4e80-980f-86ca4793c029",
   "metadata": {},
   "source": [
    "Immediately after seeing this, I realized that inventory is likely our culprit. It stands to reason that a seller often has only one of these specific guitars in inventory, and if it's sold, the seller's inventory will be 0. Of course, we won't have this information when we create a post, so it cannot be included in our features. Removing it, we can see below a much more realistic model. \n",
    "\n",
    "Since we've limited the amount of features, it's great to see that our training and validation scores are so close, this means we're not dealing with a model that's overfitting to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "id": "5f051dad-bf0a-4653-b072-a96180227211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score:\t0.8019257221458047\n",
      "Validation F1 Score: \t0.8041237113402062\n",
      "[[120  39]\n",
      " [ 56 195]]\n"
     ]
    }
   ],
   "source": [
    "included_features_no_leak = included_features\n",
    "included_features_no_leak[0] = False\n",
    "\n",
    "logreg3 = LogisticRegression(max_iter=10000, random_state=100)\n",
    "logreg3.fit(X_train.iloc[:,included_features_no_leak], y_train)\n",
    "y_pred_train = logreg3.predict(X_train.iloc[:,included_features_no_leak])\n",
    "y_pred_val = logreg3.predict(X_val.iloc[:,included_features_no_leak])\n",
    "\n",
    "print('Training F1 Score:\\t{}'.format(f1_score(y_train, y_pred_train)))\n",
    "print('Validation F1 Score: \\t{}'.format(f1_score(y_val, y_pred_val)))\n",
    "print(confusion_matrix(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b7be8-09d8-4c1c-b494-27c45462c632",
   "metadata": {},
   "source": [
    "I was also curious to see if there were any other features that may be worth including. I was surprised to see such a strong negative correlation with the \"Brand New\" condition, but think this definitely justifies its inclusion as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "id": "94bc319e-447c-49e2-aa4d-849462f92a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_sold                             1.000000\n",
       "condition.display_name_Mint         0.325487\n",
       "condition.display_name_Excellent    0.261010\n",
       "upc_does_not_apply_True             0.250281\n",
       "klarna_accepted_True                0.193083\n",
       "                                      ...   \n",
       "shop.preferred_seller_True         -0.249956\n",
       "has_inventory_True                 -0.372589\n",
       "days_to_return_int                 -0.384622\n",
       "inventory                          -0.402008\n",
       "condition.display_name_Brand New   -0.542157\n",
       "Name: is_sold, Length: 68, dtype: float64"
      ]
     },
     "execution_count": 1170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.merge(y, X, left_index=True, right_index=True)\n",
    "full_df.corr().sort_values(by='is_sold', ascending=False).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "id": "9ea52500-396b-4b3a-aa07-16fd167f3718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score:\t0.8019257221458047\n",
      "Validation F1 Score: \t0.8041237113402062\n",
      "[[120  39]\n",
      " [ 56 195]]\n"
     ]
    }
   ],
   "source": [
    "included_features_no_leak[25] = True\n",
    "\n",
    "logreg2 = LogisticRegression(max_iter=10000, random_state=100)\n",
    "logreg2.fit(X_train.iloc[:,included_features_no_leak], y_train)\n",
    "y_pred_train = logreg2.predict(X_train.iloc[:,included_features_no_leak])\n",
    "y_pred_val = logreg2.predict(X_val.iloc[:,included_features_no_leak])\n",
    "\n",
    "print('Training F1 Score:\\t{}'.format(f1_score(y_train, y_pred_train)))\n",
    "print('Validation F1 Score: \\t{}'.format(f1_score(y_val, y_pred_val)))\n",
    "print(confusion_matrix(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de682564-3cdd-4075-985e-2fd83b6e9d11",
   "metadata": {},
   "source": [
    "Next, I'm curious to see how some more powerful models would perform on this dataset. These functions are chained together to instantiate, fit, and score a few different models automatically. In this case, we are trying our baseline logistic regression model, a random forest classifier, and an XGBoost classifier. See the table below for results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "id": "761629a3-17a8-4653-8f77-bfe2275ef7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>val_conf_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.801926</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>[[120, 39], [56, 195]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>0.928287</td>\n",
       "      <td>[[141, 18], [18, 233]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.930140</td>\n",
       "      <td>[[142, 17], [18, 233]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model     train       val         val_conf_matrix\n",
       "0  logistic regression  0.801926  0.804124  [[120, 39], [56, 195]]\n",
       "1        random forest  0.999341  0.928287  [[141, 18], [18, 233]]\n",
       "2              xgboost  0.999340  0.930140  [[142, 17], [18, 233]]"
      ]
     },
     "execution_count": 1186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def instantiate_and_fit(model_type, X_train, y_train, X_val, y_val):\n",
    "    model = model_type\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    return (y_pred_train, y_pred_val)\n",
    "\n",
    "def train_and_score(X_train, y_train, X_val, y_val):\n",
    "    rmse_results = pd.DataFrame(columns = ['model', 'train', 'val', 'val_conf_matrix'])\n",
    "    \n",
    "    # Logistic Regression\n",
    "    y_pred_train, y_pred_val = instantiate_and_fit(LogisticRegression(max_iter=10000, random_state=100), \n",
    "                                                   X_train.iloc[:,included_features_no_leak], \n",
    "                                                   y_train, \n",
    "                                                   X_val.iloc[:,included_features_no_leak], \n",
    "                                                   y_val)\n",
    "    rmse_results.loc[len(rmse_results)] = ['logistic regression', \n",
    "                                           f1_score(y_train, y_pred_train), \n",
    "                                           f1_score(y_val, y_pred_val),\n",
    "                                           confusion_matrix(y_val, y_pred_val)]\n",
    "    \n",
    "    # Random Forest Classifier\n",
    "    y_pred_train, y_pred_val = instantiate_and_fit(RandomForestClassifier(random_state=100), \n",
    "                                                   X_train.iloc[:,included_features_no_leak], \n",
    "                                                   y_train, \n",
    "                                                   X_val.iloc[:,included_features_no_leak], \n",
    "                                                   y_val)\n",
    "    rmse_results.loc[len(rmse_results)] = ['random forest', \n",
    "                                           f1_score(y_train, y_pred_train), \n",
    "                                           f1_score(y_val, y_pred_val),\n",
    "                                           confusion_matrix(y_val, y_pred_val)]\n",
    "    \n",
    "    # XGBoost Classifier\n",
    "    y_pred_train, y_pred_val = instantiate_and_fit(XGBClassifier(random_state=100), \n",
    "                                                   X_train.iloc[:,included_features_no_leak].astype(float), \n",
    "                                                   y_train, \n",
    "                                                   X_val.iloc[:,included_features_no_leak].astype(float), \n",
    "                                                   y_val)\n",
    "    rmse_results.loc[len(rmse_results)] = ['xgboost', \n",
    "                                           f1_score(y_train, y_pred_train), \n",
    "                                           f1_score(y_val, y_pred_val),\n",
    "                                           confusion_matrix(y_val, y_pred_val)]\n",
    "    \n",
    "    return rmse_results\n",
    "\n",
    "train_and_score(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f9f20-ad2f-4c80-aec5-4ced1e6eca0f",
   "metadata": {},
   "source": [
    "Again we see some good news that random forest and xgboost classifiers perform even better than our logistic regression model. In this case, I'm going to stick with XGBoost and next ensure that our hyperparameters are as optimal as possible.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "We're going to use sklearn's GridSearchCV function to try out a handful of hyperparameter combinations and see what performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "id": "0c5a2353-7323-478a-acd5-dadab270ba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 100}"
      ]
     },
     "execution_count": 1187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=100)\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(60, 220, 40),\n",
    "    'learning_rate': [0.1, 0.01, 0.05]}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=parameters,\n",
    "    scoring = 'f1',\n",
    "    n_jobs = 10,\n",
    "    cv = 10,\n",
    "    verbose=True)\n",
    "\n",
    "grid_search.fit(X.iloc[:,included_features_no_leak].astype(float), y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42bd042-c563-4865-b614-d82f52a857fb",
   "metadata": {},
   "source": [
    "Using our strongest hyperparameters, we'll run the model one last time, and also pull in our test data to see how our model performs on data it has not seen at all during this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "id": "f52ec8be-2297-4857-ac8a-6b8cad253f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score:\t0.9405684754521965\n",
      "Validation F1 Score: \t0.916504854368932\n",
      "Test F1 Score: \t0.9336016096579477\n",
      "[[146  22]\n",
      " [ 11 232]]\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(learning_rate=0.01, max_depth=7, n_estimators=60, random_state=100)\n",
    "xgb2.fit(X_train.iloc[:,included_features_no_leak].astype(float), y_train)\n",
    "y_pred_train = xgb2.predict(X_train.iloc[:,included_features_no_leak].astype(float))\n",
    "y_pred_val = xgb2.predict(X_val.iloc[:,included_features_no_leak].astype(float))\n",
    "y_pred_test = xgb2.predict(X_test.iloc[:,included_features_no_leak].astype(float))\n",
    "\n",
    "print('Training F1 Score:\\t{}'.format(f1_score(y_train, y_pred_train)))\n",
    "print('Validation F1 Score: \\t{}'.format(f1_score(y_val, y_pred_val)))\n",
    "print('Test F1 Score: \\t{}'.format(f1_score(y_test, y_pred_test)))\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef148a-9ae4-45e0-96d2-cc1803744188",
   "metadata": {},
   "source": [
    "I'm very happy to see an F1 score of .933! As stated above, seeing that all of our scores are right around the same value means our model is not overfitting the training data, and seeing F1 scores into the mid-90's is strong evidence that we're not dealing with high bias/underfitting.\n",
    "\n",
    "The last part of this model we have not explored very deeply is feature importance. We know these features are a good combination for making predictions, but I'm curious which features among these are the most valuable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "id": "8736781b-71f1-4eed-ac61-8409fe86f8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 1197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_idx = xgb2.feature_importances_.argsort()\n",
    "plt.barh(X_train.iloc[:,included_features_no_leak].columns[sorted_idx], xgb2.feature_importances_[sorted_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2149f36c-4830-49c4-a964-f64cc307acb0",
   "metadata": {},
   "source": [
    "I was originally really surprised by how important the \"Brand New\" condition was to this model, so I compared this to the Reverb search results. The majority of unsold guitars are under the category \"Brand New\" (about 70%). It looks like many of these are established guitar retailers posting their inventory to Reverb. In contrast, only about 25% of the sold guitars are \"Brand New\". It seems clear to me that people are not using Reverb to buy new products, which absolutely aligns with my personal experience. Otherwise, these seem like very reasonable features to predict sales.\n",
    "\n",
    "Based on the features in this model, my advice to those selling music equipment on Reverb is as follows:\n",
    "- Mark equipment as \"Mint\" instead of \"Brand New\" if appropriate\n",
    "- Shoppers are of course more likely to buy from a shop with a good rating (On Reverb, users get rated for buying products as well, which is a good way to build up a positive account rating.)\n",
    "- Price as competitively as possible, Reverb has tools to help determine exact values.\n",
    "- Enable offers, people are more likely to make an offer/negotiate price than buy equipment outright.\n",
    "- Include as long a return policy as possible.\n",
    "- Include a good amount of photos in the posting, this gives shoppers more confidence in what they're buying."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
